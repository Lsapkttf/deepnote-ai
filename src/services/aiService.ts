
import { AIAnalysis } from '../types/note';
import { toast } from "sonner";

// Cl√© API Gemini
const API_KEY = 'AIzaSyAdOinCnHfqjOyk6XBbTzQkR_IOdRvlliU';

// Stockage en m√©moire des conversations pour chaque note
interface ConversationMemory {
  [noteId: string]: {
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
  }[];
}

// Initialiser la m√©moire de conversation
const conversationMemory: ConversationMemory = {};

// Fonction pour analyser le texte avec Gemini
export const analyzeText = async (text: string): Promise<AIAnalysis> => {
  try {
    if (!text || text.trim().length === 0) {
      throw new Error("Aucun texte √† analyser");
    }

    console.log("D√©marrage de l'analyse avec Gemini...");
    
    const prompt = `Voici une note: "${text.substring(0, 4000)}${text.length > 4000 ? '...' : ''}"

Je voudrais que tu me fournisses:
1. Un r√©sum√© bref (2-3 phrases)
2. Les points cl√©s (liste de 3-5 points)
3. Le sentiment g√©n√©ral exprim√© (positif, n√©gatif ou neutre)

R√©ponds avec un format clairement structur√©:

R√©sum√©:
[Ton r√©sum√© ici]

Points cl√©s:
- [Premier point]
- [Deuxi√®me point]
- [Troisi√®me point]
- [Etc. si n√©cessaire]

Sentiment:
[positif/n√©gatif/neutre]`;

    const response = await fetch(
      'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=' + API_KEY,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [
            {
              role: "user",
              parts: [
                { text: prompt }
              ]
            }
          ],
          generationConfig: {
            temperature: 0.5,
            maxOutputTokens: 500,
          }
        }),
      }
    );

    if (!response.ok) {
      const errorData = await response.json();
      console.error("Erreur API Gemini:", errorData);
      throw new Error(`Erreur de connexion: ${response.status} - ${errorData?.error?.message || 'Erreur inconnue'}`);
    }

    const result = await response.json();
    console.log("R√©ponse brute:", result);
    
    if (result.candidates && result.candidates.length > 0 && result.candidates[0].content) {
      const generatedText = result.candidates[0].content.parts[0].text;
      console.log("Texte g√©n√©r√©:", generatedText);
      
      // Extraction des parties du texte
      const summary = extractSummary(generatedText);
      const keyPoints = extractKeyPoints(generatedText);
      const sentiment = extractSentiment(generatedText);

      return {
        summary,
        keyPoints,
        sentiment
      };
    } else {
      throw new Error("Format de r√©ponse inattendu");
    }
  } catch (error) {
    console.error("Erreur d'analyse:", error);
    toast.error("Erreur lors de l'analyse du texte");
    
    // Retourner des valeurs par d√©faut en cas d'erreur
    return {
      summary: "Impossible d'analyser le texte",
      keyPoints: ["Erreur lors de l'analyse", "Veuillez r√©essayer ult√©rieurement"],
      sentiment: "neutre"
    };
  }
};

// Fonction pour le chat IA
export const chatWithAI = async (message: string, noteContent: string, noteId?: string): Promise<string> => {
  try {
    if (!message || message.trim().length === 0) {
      throw new Error("Message vide");
    }

    console.log("Envoi au chat IA via Gemini:", message);
    
    // Limiter la taille du contenu de la note pour √©viter les d√©passements
    const trimmedContent = noteContent.length > 3000 
      ? noteContent.substring(0, 3000) + "..." 
      : noteContent;
    
    let systemPrompt = "Tu es un assistant qui r√©pond √† des questions sur le contenu d'une note. R√©ponds uniquement en te basant sur les informations fournies dans la note. Si la r√©ponse n'est pas dans le contenu, dis-le simplement. R√©ponds de fa√ßon dynamique et engageante avec des emojis adapt√©s au contexte.";
    
    // Adapter le prompt syst√®me en fonction du contexte (note sp√©cifique ou assistant g√©n√©ral)
    if (noteId === "general") {
      systemPrompt = "Tu es DeepNote Assistant, un assistant IA con√ßu pour aider les utilisateurs √† g√©rer leurs notes et leurs id√©es. Tu es serviable, pr√©cis et concis. Tu peux aider √† cr√©er du contenu pour des notes, sugg√©rer des id√©es d'organisation, et r√©pondre √† diverses questions. R√©ponds toujours en fran√ßais avec un style dynamique et engageant en utilisant des emojis appropri√©s. Sois cr√©atif et utile.";
    }
    
    // Construire le contenu du message en fonction du contexte
    let userMessageContent = message;
    
    // Si c'est une note sp√©cifique (pas l'assistant g√©n√©ral), inclure le contenu de la note
    if (noteId !== "general" && trimmedContent) {
      userMessageContent = `Contexte (contenu de la note): "${trimmedContent}"

Question: ${message}`;
    }
    
    // Construire les messages pour l'API Gemini
    const contents = [];
    
    // Ajouter le message syst√®me
    contents.push({
      role: "model",
      parts: [{ text: systemPrompt }]
    });
    
    // Ajouter l'historique de conversation si disponible pour cette note
    if (noteId && conversationMemory[noteId]) {
      const history = conversationMemory[noteId];
      // Limiter l'historique aux 10 derniers √©changes pour √©viter les d√©passements de tokens
      const recentHistory = history.slice(-10);
      
      recentHistory.forEach(msg => {
        contents.push({
          role: msg.role === 'user' ? 'user' : 'model',
          parts: [{ text: msg.content }]
        });
      });
    }
    
    // Ajouter le message actuel de l'utilisateur
    contents.push({
      role: "user",
      parts: [{ text: userMessageContent }]
    });
    
    const response = await fetch(
      'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=' + API_KEY,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: contents,
          generationConfig: {
            temperature: 0.8,
            maxOutputTokens: 800,
          }
        }),
      }
    );

    if (!response.ok) {
      const errorData = await response.json();
      console.error("Erreur API Gemini chat:", errorData);
      throw new Error(`Erreur de connexion: ${response.status} - ${errorData?.error?.message || 'Erreur inconnue'}`);
    }

    const result = await response.json();
    console.log("R√©ponse brute du chat:", result);
    
    if (result.candidates && result.candidates.length > 0 && result.candidates[0].content) {
      const generatedText = result.candidates[0].content.parts[0].text;
      console.log("R√©ponse g√©n√©r√©e:", generatedText);
      
      // Sauvegarder dans l'historique de conversation si noteId est fourni
      if (noteId) {
        if (!conversationMemory[noteId]) {
          conversationMemory[noteId] = [];
        }
        
        // Sauvegarder la question de l'utilisateur
        conversationMemory[noteId].push({
          role: 'user',
          content: message,
          timestamp: new Date()
        });
        
        // Sauvegarder la r√©ponse de l'assistant
        conversationMemory[noteId].push({
          role: 'assistant',
          content: generatedText,
          timestamp: new Date()
        });
      }
      
      return generatedText.trim();
    } else {
      throw new Error("Format de r√©ponse inattendu");
    }
  } catch (error) {
    console.error("Erreur de chat:", error);
    
    if (error instanceof Error) {
      return `üôÅ D√©sol√©, je n'ai pas pu r√©pondre. Erreur: ${error.message}`;
    } else {
      return "üôÅ D√©sol√©, une erreur est survenue lors de la communication avec l'IA.";
    }
  }
};

// Fonction pour r√©cup√©rer l'historique des conversations pour une note
export const getChatHistory = (noteId: string) => {
  return conversationMemory[noteId] || [];
};

// Fonction pour la transcription audio (toujours via Whisper car Gemini n'a pas d'API de transcription √©quivalente)
export const transcribeAudio = async (audioBlob: Blob): Promise<string> => {
  try {
    console.log("D√©but de la transcription audio...");
    
    // Cr√©er un FormData pour envoyer le fichier audio
    const formData = new FormData();
    formData.append('file', audioBlob, 'audio.wav');
    formData.append('model', 'whisper-1');
    
    // Pour la transcription, nous continuons d'utiliser l'API Whisper d'OpenAI
    // puisque Gemini n'a pas d'√©quivalent direct pour la transcription audio
    const response = await fetch(
      'https://api.openai.com/v1/audio/transcriptions',
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${API_KEY}`,
        },
        body: formData,
      }
    );

    if (!response.ok) {
      console.error("Erreur API transcription:", await response.text());
      return "La transcription audio n'est pas disponible. Veuillez entrer le texte manuellement.";
    }

    const result = await response.json();
    console.log("Transcription r√©ussie:", result);
    return result.text || "";
  } catch (error) {
    console.error("Erreur de transcription:", error);
    toast.error("Erreur lors de la transcription audio");
    return "La transcription audio n'est pas disponible actuellement. Veuillez entrer le texte manuellement.";
  }
};

// Fonctions utilitaires pour extraire les informations de la r√©ponse de l'IA
function extractSummary(text: string): string {
  // Rechercher le r√©sum√© entre "R√©sum√©:" et la prochaine section
  const summaryMatch = text.match(/R√©sum√©\s*:(.*?)(?=Points cl√©s|$)/is);
  if (summaryMatch && summaryMatch[1]) {
    return summaryMatch[1].trim();
  }
  
  // Fallback: prendre les premi√®res lignes qui ne contiennent pas "Points cl√©s" ou "Sentiment"
  const lines = text.split('\n').filter(line => {
    const lowerLine = line.toLowerCase();
    return !lowerLine.includes('points cl√©s') && !lowerLine.includes('sentiment');
  });
  
  if (lines.length > 0) {
    return lines.slice(0, 3).join(' ').trim();
  }
  
  return "R√©sum√© non disponible";
}

function extractKeyPoints(text: string): string[] {
  // Chercher la section des points cl√©s
  const keyPointsMatch = text.match(/Points cl√©s\s*:(.*?)(?=Sentiment|$)/is);
  
  if (keyPointsMatch && keyPointsMatch[1]) {
    // Extraire les points (format liste avec tirets)
    const pointsText = keyPointsMatch[1].trim();
    const points = pointsText.split(/\n-|\n‚Ä¢|\n\*/)
      .map(point => point.trim())
      .filter(point => point.length > 0 && !point.startsWith('Points cl√©s'));
    
    if (points.length > 0) {
      return points;
    }
  }
  
  // Rechercher des lignes qui ressemblent √† des points de liste dans tout le texte
  const listItems = text.match(/(?:^|\n)[-‚Ä¢*]\s*(.*?)(?=$|\n)/g);
  if (listItems && listItems.length > 0) {
    return listItems.map(item => item.replace(/^[-‚Ä¢*\s]+/, '').trim());
  }
  
  return ["Points cl√©s non disponibles"];
}

function extractSentiment(text: string): string {
  // Rechercher la mention explicite du sentiment
  const sentimentMatch = text.match(/Sentiment\s*:(.*?)(?=$)/is);
  
  if (sentimentMatch && sentimentMatch[1]) {
    const sentimentText = sentimentMatch[1].trim().toLowerCase();
    
    if (sentimentText.includes("positif")) {
      return "positif";
    }
    else if (sentimentText.includes("n√©gatif")) {
      return "n√©gatif";
    }
  }
  
  // Rechercher des mots-cl√©s de sentiment dans tout le texte
  const lowerText = text.toLowerCase();
  if (lowerText.includes("sentiment") && lowerText.includes("positif")) {
    return "positif";
  }
  else if (lowerText.includes("sentiment") && lowerText.includes("n√©gatif")) {
    return "n√©gatif";
  }
  
  return "neutre";
}

// Pour compatibilit√© avec le code existant
export const setHuggingFaceApiKey = (key: string) => {
  console.log("Note: La cl√© API est maintenant fixe (Gemini)");
  localStorage.setItem('gemini_api_key', API_KEY);
};

export const getHuggingFaceApiKey = (): string => {
  return API_KEY;
};

export const checkApiKey = (): boolean => {
  return true; // Toujours vrai car la cl√© est fixe
};
